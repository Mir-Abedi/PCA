{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v2qUM9rYj2L5"
   },
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "<font face=\"XB Zar\" size=5>\n",
    "<div align=center>\n",
    "    <font size=6>\n",
    "    باسمه تعالی\n",
    "    </font>\n",
    "    <br><br>\n",
    "    <font>\n",
    "    درس جبر خطی\n",
    "    <br>\n",
    "        <font size=3>\n",
    "            مدرس: حمیدرضا ربیعی، مریم رمضانی\n",
    "        </font>\n",
    "    </font>\n",
    "    <br><br>\n",
    "    <font>\n",
    "        <b> PyTorch پروژه</b>\n",
    "    </font>\n",
    "    <br>\n",
    "    <font size=3>\n",
    "     موعد تحویل: ۱۵ بهمن ۱۴۰۰ ساعت ۲۳:۵۹\n",
    "    </font>\n",
    "    <br>\n",
    "    <font size=4>\n",
    "    دستیاران آموزشی:\n",
    "        پویا اسمعیلی،\n",
    "        علی بالاپور\n",
    "    </font>\n",
    "    <br>\n",
    "        <font size=2>\n",
    "        دانشگاه صنعتی شریف\n",
    "        <br>\n",
    "        دانشکده مهندسی کامپیوتر\n",
    "    </font>\n",
    "</div>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ie0Z27UOj2MH"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    <h1>مقدمه</h1>\n",
    "    هدف این پروژه تعمیق مفاهیم تدریس شده در کلاس درس  و آشنایی دانشجویان با کاربردهای جبرخطی است. برای انجام این پروژه، نکات زیر را در نظر داشته باشید:\n",
    "    <ul>\n",
    "        <li>یکی از اهداف این پروژه آشنایی بیشتر دانشجویان با توابع و مفاهیم PyTorch است. بنابراین پیاده‌سازی خواسته‌های هر سوال حتما باید با استفاده از PyTorch باشد.</li>\n",
    "        <li>انجام این پروژه به صورت انفرادی است.</li>\n",
    "        <li>در مجموع این پروژه 100 نمره بوده که سوال اول 40 نمره و سوال دوم 60 نمره دارد. توجه داشته باشید پیاده‌سازی این پروژه اختیاری بوده و نمره اختصاص شده برابر 0.8 از نمره کل است.</li>\n",
    "        <li>توجه داشته باشید که نمی‌توانید از تاخیر مجاز برای این پروژه استفاده نمایید. (به علت اختیاری بودن پروژه و همچنین نزدیک بودن ددلاین به مهلت ارسال نمرات به آموزش)</li>\n",
    "        <li>پس از ددلاین مشخص شده برای پروژه، یک جلسه کوتاه برای تحویل حضوری پروژه برگزار می‌گردد.</li>\n",
    "        <li>برای راحتی کار، توصیه می‌شود که از google colab استفاده نمایید.</li>\n",
    "        <li>\n",
    "        برای این پروژه لازم است که علاوه بر پیاده‌سازی خواسته سوال، توضیح کوتاهی در مورد نحوه عملکرد کد پیاده‌سازی‌شده نوشته شود.\n",
    "        </li>\n",
    "    </ul>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gV_5Tc2fj2MJ"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=3>\n",
    "    <h1>الگوریتم PCA </h1>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WT1F0AZSj2MK"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "    در این تمرین قصد داریم که با استفاده از فریمورک PyTorch و ابزارهای آن، الگوریتم \n",
    "    <a href='https://en.wikipedia.org/wiki/Principal_component_analysis'>PCA (Principal Component Analysis)</a> را روی دیتاست Iris پیاده‌سازی کنیم.  <br>\n",
    "دیتاستی که در این قسمت در نظر گرفته‌شده، دیتاست iris است. این دیتاست شامل داده‌های سه نوع گل زنبق بوده که بر اساس 4 ویژگی، دسته‌بندی شده‌اند (در جلسات اولیه درس در مورد این دیتاست صحبت کردیم). یکی از اقدامات ابتدایی در یک پروژه مربوط به یادگیری ماشین و علوم داده، \n",
    "    <a href=''https://en.wikipedia.org/wiki/Exploratory_data_analysis>EDA(Exploratory Data Analysis)</a>\n",
    "    است. در EDA قصد داریم تا با رسم نمودارهای مختلف و استفاده از ابزارهای موجود، یک دید کلی نسبت به داده بدست بیاوریم. اما برای رسم ساده‌ترین نمودارها (مانند نمودار scatter) برای داده‌هایی که دارای بیش از دو یا سه ویژگی دارند، ممکن است دشوار باشد. برای همین از الگوریتم‌های کاهش ابعاد استفاده می‌گردد. مشهورترین الگوریتم‌ها برای این کار، PCA و t-SNE می‌باشند. <br>\n",
    "در این تمرین شما باید دیتاست \n",
    "    <a href='https://archive.ics.uci.edu/ml/datasets/iris'>Iris</a>\n",
    "    (که در فایل iris.csv قرار دارد) را به یک تنسور دو بعدی تبدیل نمایید و الگوریتم PCA را با استفاده از توابع محاسباتی و مربوط به جبرخطی پایتورچ، بر روی این تنسور پیاده‌سازی کنید. سپس نتایج به‌دست آمده را با استفاده از کتابخانه‌های مصورسازی پایتون (مانند pyplot) بر روی یک scatter plot (با اعمال برچسب هر داده) رسم کنید. <br>\n",
    "توجه داشته باشید که استفاده از هرگونه کتابخانه برای پیاده‌سازی مستقیم الگوریتم PCA مجاز نیست. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Kf0K30Slj2MM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>146</td>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>147</td>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>148</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>149</td>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>150</td>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0      1            5.1           3.5            1.4           0.2   \n",
       "1      2            4.9           3.0            1.4           0.2   \n",
       "2      3            4.7           3.2            1.3           0.2   \n",
       "3      4            4.6           3.1            1.5           0.2   \n",
       "4      5            5.0           3.6            1.4           0.2   \n",
       "..   ...            ...           ...            ...           ...   \n",
       "145  146            6.7           3.0            5.2           2.3   \n",
       "146  147            6.3           2.5            5.0           1.9   \n",
       "147  148            6.5           3.0            5.2           2.0   \n",
       "148  149            6.2           3.4            5.4           2.3   \n",
       "149  150            5.9           3.0            5.1           1.8   \n",
       "\n",
       "            Species  \n",
       "0       Iris-setosa  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "..              ...  \n",
       "145  Iris-virginica  \n",
       "146  Iris-virginica  \n",
       "147  Iris-virginica  \n",
       "148  Iris-virginica  \n",
       "149  Iris-virginica  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = []\n",
    "cols = 0\n",
    "for i in df.columns:\n",
    "    if i in ('Species', 'Id'):\n",
    "        continue\n",
    "    cols += 1\n",
    "    arr.extend(df[i])\n",
    "df    \n",
    "len(arr)\n",
    "\n",
    "t = torch.tensor(arr).reshape(cols, -1).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.1000, 3.5000, 1.4000, 0.2000],\n",
       "        [4.9000, 3.0000, 1.4000, 0.2000],\n",
       "        [4.7000, 3.2000, 1.3000, 0.2000],\n",
       "        [4.6000, 3.1000, 1.5000, 0.2000],\n",
       "        [5.0000, 3.6000, 1.4000, 0.2000],\n",
       "        [5.4000, 3.9000, 1.7000, 0.4000],\n",
       "        [4.6000, 3.4000, 1.4000, 0.3000],\n",
       "        [5.0000, 3.4000, 1.5000, 0.2000],\n",
       "        [4.4000, 2.9000, 1.4000, 0.2000],\n",
       "        [4.9000, 3.1000, 1.5000, 0.1000],\n",
       "        [5.4000, 3.7000, 1.5000, 0.2000],\n",
       "        [4.8000, 3.4000, 1.6000, 0.2000],\n",
       "        [4.8000, 3.0000, 1.4000, 0.1000],\n",
       "        [4.3000, 3.0000, 1.1000, 0.1000],\n",
       "        [5.8000, 4.0000, 1.2000, 0.2000],\n",
       "        [5.7000, 4.4000, 1.5000, 0.4000],\n",
       "        [5.4000, 3.9000, 1.3000, 0.4000],\n",
       "        [5.1000, 3.5000, 1.4000, 0.3000],\n",
       "        [5.7000, 3.8000, 1.7000, 0.3000],\n",
       "        [5.1000, 3.8000, 1.5000, 0.3000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.1967, 0.2406, 0.0780, 0.0235])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demeaned_mat = []\n",
    "cov_mat = []\n",
    "for i in range(cols):\n",
    "    m = torch.mean(t[:, i])\n",
    "    for j in t[:, i]:\n",
    "        demeaned_mat.append(j - m)\n",
    "\n",
    "demeaned_mat = torch.tensor(demeaned_mat).reshape(cols, -1).T\n",
    "\n",
    "\n",
    "l = len(demeaned_mat[:, 0])\n",
    "for i in range(cols):\n",
    "    for j in range(cols):\n",
    "        cov_mat.append(torch.dot(demeaned_mat[:, i], demeaned_mat[:, j])/l)\n",
    "cov_mat = torch.tensor(cov_mat).reshape(cols, cols)\n",
    "\n",
    "\n",
    "eig_vals, eig_vecs = map(torch.real, torch.linalg.eig(cov_mat))\n",
    "eig_vals = torch.abs(eig_vals)\n",
    "\n",
    "s = torch.argsort(eig_vals, descending = True)\n",
    "\n",
    "num_basis = 2\n",
    "max_args = []\n",
    "for i in range(num_basis):\n",
    "    max_args.append(s[i])\n",
    "\n",
    "basis = torch.tensor([]).reshape(cols, -1)\n",
    "\n",
    "for i in max_args:\n",
    "    basis = torch.cat((basis, eig_vecs[:, i].reshape(-1, 1)), 1)\n",
    "    pass\n",
    "\n",
    "basis\n",
    "\n",
    "reduced_t = torch.matmul(t, basis)\n",
    "reduced_t[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x250633e7df0>"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.scatter(reduced_t[:, 0], reduced_t[:, 1], s = 10, c = )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quSZ9Ea-j2MP"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=3>\n",
    "    <h1>سیستم توصیه‌گر (Recommender System)</h1>\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SltwmPLRj2MP"
   },
   "source": [
    "<div align= \"justify\" dir=\"rtl\">\n",
    "<font face=\"Calibri\" size=4>\n",
    "در این تمرین قصد داریم که با استفاده از فریمورک PyTorch و ابزارهای آن، یک سیستم توصیه‌گر (یا recommender system) ساده را پیاده‌سازی کنیم.\n",
    "<br> \n",
    "برای پیاده‌سازی این سیستم، شما یک جدول از امتیاز کاربران (از ۱ تا ۵) به فیلم‌ها دارید (در فایل ratings.csv). ستون‌های این جدول، شناسه‌ی کاربر، شناسه‌ی فیلم و امتیاز هستند. برای استفاده از این داده‌ها باید آن‌ها را تبدیل به ماتریسی از امتیاز هر کاربر به هر فیلم کنید. البته باید توجه کنید بیشتر درایه‌های این ماتریس نامشخص (امتیاز صفر) بوده و لازم است به جای ‌ان‌ها یک عدد قرار دهید. در ادامه روش‌های مختلف پر کردن این درایه‌ها توضیح داده می‌شود.\n",
    "<br>\n",
    "برای بررسی عملکرد سیستم، \n",
    "<!-- لازم است ابتدا تعدادی از داده‌های اولیه جدا شوند. بنابراین ۱۰ درصد از سطرهای جدول اولیه را به طور رندوم جدا کرده و از جدول حذف کنید. حال -->\n",
    " سیستم توصیه‌گر شما با یادگیری داده‌ها، امتیازی از طرف هر کاربر به هر فیلم نسبت می‌دهد. اگر این امتیازها را $y$ نامیده و امتیاز‌های حذف شده از جدول اولیه $\\hat{y}$ باشند، خطای سیستم به صورت\n",
    "$$E = \\Sigma_i (y - \\hat{y})^2$$\n",
    "تعریف می‌شود. برای هر یک از راه‌حل‌های خود، این خطا را برای خانه‌هایی که در دیتاست اولیه مقادیر بین ۱ تا ۵ دارند، حساب کنید.\n",
    "<br>\n",
    "در طراحی سیستم می‌توانید از تجزیه‌ی SVD استفاده کنید. برای این کار باید ابتدا درایه‌های نامشخص را پر کنید. برای این کار، روش‌های زیر را امتحان کرده و خطای سیستم در هر حالت را مقایسه کنید. سپس، از بهترین روش در سیستم نهایی خود استفاده کنید.\n",
    "<ol>\n",
    "<li>قرار دادن صفر به جای همه‌ی مقادیر نامشخص</li>\n",
    "<li>قرار دادن میانگین امتیاز هر فیلم در درایه‌های نامشخص آن فیلم</li>\n",
    "<li>استفاده از میانه‌ی امتیازهای هر فیلم در درایه‌های نامشخص آن فیلم</li>\n",
    "</ol>\n",
    "<br> \n",
    "برای این تمرین لازم است که شما با استفاده از مفاهیم تدریس شده در کلاس درس و ابزارهای پایتورچ، این سیستم توصیه گر ساده را پیاده‌سازی کنید و خطای آن را محاسبه کنید. استفاده از ابزارهای pandas و matplotlib در کنار pytorch مجاز بوده و هر گونه استفاده از numpy غیر مجاز است.\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "uPfJfQtAj2MU"
   },
   "outputs": [],
   "source": [
    "rates = pd.read_csv('ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>242</td>\n",
       "      <td>3</td>\n",
       "      <td>881250949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>302</td>\n",
       "      <td>3</td>\n",
       "      <td>891717742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>377</td>\n",
       "      <td>1</td>\n",
       "      <td>878887116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>244</td>\n",
       "      <td>51</td>\n",
       "      <td>2</td>\n",
       "      <td>880606923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>166</td>\n",
       "      <td>346</td>\n",
       "      <td>1</td>\n",
       "      <td>886397596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>99995</td>\n",
       "      <td>880</td>\n",
       "      <td>476</td>\n",
       "      <td>3</td>\n",
       "      <td>880175444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>99996</td>\n",
       "      <td>716</td>\n",
       "      <td>204</td>\n",
       "      <td>5</td>\n",
       "      <td>879795543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>99997</td>\n",
       "      <td>276</td>\n",
       "      <td>1090</td>\n",
       "      <td>1</td>\n",
       "      <td>874795795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>99998</td>\n",
       "      <td>13</td>\n",
       "      <td>225</td>\n",
       "      <td>2</td>\n",
       "      <td>882399156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>99999</td>\n",
       "      <td>12</td>\n",
       "      <td>203</td>\n",
       "      <td>3</td>\n",
       "      <td>879959583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  userId  movieId  rating  timestamp\n",
       "0               0     196      242       3  881250949\n",
       "1               1     186      302       3  891717742\n",
       "2               2      22      377       1  878887116\n",
       "3               3     244       51       2  880606923\n",
       "4               4     166      346       1  886397596\n",
       "...           ...     ...      ...     ...        ...\n",
       "99995       99995     880      476       3  880175444\n",
       "99996       99996     716      204       5  879795543\n",
       "99997       99997     276     1090       1  874795795\n",
       "99998       99998      13      225       2  882399156\n",
       "99999       99999      12      203       3  879959583\n",
       "\n",
       "[100000 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.9600e+02, 2.4200e+02, 3.0000e+00, 8.8125e+08],\n",
       "        [1.8600e+02, 3.0200e+02, 3.0000e+00, 8.9172e+08],\n",
       "        [2.2000e+01, 3.7700e+02, 1.0000e+00, 8.7889e+08],\n",
       "        [2.4400e+02, 5.1000e+01, 2.0000e+00, 8.8061e+08],\n",
       "        [1.6600e+02, 3.4600e+02, 1.0000e+00, 8.8640e+08],\n",
       "        [2.9800e+02, 4.7400e+02, 4.0000e+00, 8.8418e+08],\n",
       "        [1.1500e+02, 2.6500e+02, 2.0000e+00, 8.8117e+08],\n",
       "        [2.5300e+02, 4.6500e+02, 5.0000e+00, 8.9163e+08],\n",
       "        [3.0500e+02, 4.5100e+02, 3.0000e+00, 8.8632e+08],\n",
       "        [6.0000e+00, 8.6000e+01, 3.0000e+00, 8.8360e+08],\n",
       "        [6.2000e+01, 2.5700e+02, 2.0000e+00, 8.7937e+08],\n",
       "        [2.8600e+02, 1.0140e+03, 5.0000e+00, 8.7978e+08],\n",
       "        [2.0000e+02, 2.2200e+02, 5.0000e+00, 8.7604e+08],\n",
       "        [2.1000e+02, 4.0000e+01, 3.0000e+00, 8.9104e+08],\n",
       "        [2.2400e+02, 2.9000e+01, 3.0000e+00, 8.8810e+08],\n",
       "        [3.0300e+02, 7.8500e+02, 3.0000e+00, 8.7949e+08],\n",
       "        [1.2200e+02, 3.8700e+02, 5.0000e+00, 8.7927e+08],\n",
       "        [1.9400e+02, 2.7400e+02, 2.0000e+00, 8.7954e+08],\n",
       "        [2.9100e+02, 1.0420e+03, 4.0000e+00, 8.7483e+08],\n",
       "        [2.3400e+02, 1.1840e+03, 2.0000e+00, 8.9208e+08]], dtype=torch.float64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tensor from data frame :\n",
    "\n",
    "num_cols = 0\n",
    "data_tensor = []\n",
    "\n",
    "for i in rates.columns:\n",
    "    if i in ('Unnamed: 0'):\n",
    "        continue\n",
    "    num_cols += 1\n",
    "    for j in rates[i]:\n",
    "        data_tensor.append(j)\n",
    "\n",
    "data_tensor = torch.tensor(data_tensor, dtype = torch.float64).reshape(num_cols, -1).T\n",
    "data_tensor[0:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 5, 0],\n",
       "        [0, 0, 1, 0, 0, 0, 3, 0, 4, 0, 0, 0, 4, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 2, 0, 0, 4, 0, 4, 4, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 4, 4, 4, 0, 0, 4, 0, 0, 0, 0, 0, 0, 3, 0, 0],\n",
       "        [0, 4, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [5, 4, 0, 0, 0, 5, 0, 0, 3, 4, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [4, 4, 0, 0, 0, 5, 0, 1, 0, 3, 2, 0, 0, 0, 0, 0, 0, 4, 0, 0],\n",
       "        [0, 3, 0, 0, 0, 4, 0, 0, 3, 2, 2, 0, 5, 0, 0, 0, 2, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 5, 5, 0, 3, 5, 0, 4, 2, 0, 0, 2, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 5, 4, 4, 0, 0, 0, 5, 0, 4, 0, 0, 0, 0, 0],\n",
       "        [0, 5, 0, 0, 0, 0, 0, 4, 3, 0, 5, 0, 4, 3, 0, 0, 0, 5, 0, 0],\n",
       "        [0, 0, 0, 4, 0, 0, 0, 0, 0, 3, 0, 0, 4, 0, 3, 0, 4, 0, 0, 0],\n",
       "        [0, 4, 0, 0, 0, 5, 0, 0, 5, 0, 4, 3, 3, 0, 2, 3, 5, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0],\n",
       "        [0, 0, 0, 4, 0, 4, 4, 3, 2, 3, 0, 0, 1, 0, 2, 0, 2, 2, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 0, 0, 4, 0],\n",
       "        [4, 0, 0, 0, 0, 4, 3, 2, 3, 2, 0, 0, 3, 2, 0, 3, 0, 3, 0, 2]],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tag users, tag movies, create movie data\n",
    "\n",
    "d_movie = {}\n",
    "d_users = {}\n",
    "unique_users = rates['userId'].nunique()\n",
    "unique_movies = rates['movieId'].nunique()\n",
    "\n",
    "tag = 0\n",
    "for i in rates['userId']:\n",
    "    temp = d_users.get(i)\n",
    "    if temp == None:\n",
    "        d_users[i] = tag\n",
    "        tag += 1\n",
    "    else:\n",
    "        continue\n",
    "tag = 0\n",
    "for i in rates['movieId']:\n",
    "    temp = d_movie.get(i)\n",
    "    if temp == None:\n",
    "        d_movie[i] = tag\n",
    "        tag += 1\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "approach1 = torch.zeros((unique_users, unique_movies), dtype = torch.int32)\n",
    "\n",
    "for row in rates.iterrows():\n",
    "    user_id = row[1]['userId']\n",
    "    movie_id = row[1]['movieId']\n",
    "    approach1[d_users[user_id], d_movie[movie_id]] = row[1]['rating']\n",
    "approach1[0:20, 0:20]\n",
    "    \n",
    "\n",
    "    \n",
    "# approach 1 done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.0000, 4.1616, 2.1538,  ..., 3.0000, 3.0000, 3.0000],\n",
       "        [3.9915, 3.0000, 2.1538,  ..., 3.0000, 3.0000, 3.0000],\n",
       "        [3.9915, 4.1616, 1.0000,  ..., 3.0000, 3.0000, 3.0000],\n",
       "        ...,\n",
       "        [3.9915, 4.1616, 2.1538,  ..., 3.0000, 3.0000, 3.0000],\n",
       "        [3.9915, 4.0000, 2.1538,  ..., 3.0000, 3.0000, 3.0000],\n",
       "        [3.9915, 4.1616, 2.1538,  ..., 3.0000, 3.0000, 3.0000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approach2 : mean of every movie\n",
    "\n",
    "approach2 = torch.clone(approach1)\n",
    "approach2 = approach2.to(torch.float64)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(unique_movies):\n",
    "    nnz = 0\n",
    "    s = 0\n",
    "    for j in range(unique_users):\n",
    "        if approach1[j, i] != 0:\n",
    "            s += approach1[j, i]\n",
    "            nnz += 1\n",
    "    m = s / nnz\n",
    "    for j in range(unique_users):\n",
    "        if approach1[j, i] == 0:\n",
    "            approach2[j, i] = m\n",
    "            \n",
    "approach2\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 4., 2.,  ..., 3., 3., 3.],\n",
       "        [4., 3., 2.,  ..., 3., 3., 3.],\n",
       "        [4., 4., 1.,  ..., 3., 3., 3.],\n",
       "        ...,\n",
       "        [4., 4., 2.,  ..., 3., 3., 3.],\n",
       "        [4., 4., 2.,  ..., 3., 3., 3.],\n",
       "        [4., 4., 2.,  ..., 3., 3., 3.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# approach 3 : median of every movie\n",
    "\n",
    "approach3 = torch.clone(approach1)\n",
    "approach3 = approach3.to(torch.float64)\n",
    "approach3\n",
    "\n",
    "for i in range(unique_movies):\n",
    "    temp = []\n",
    "    for j in range(unique_users):\n",
    "        if approach1[j, i] != 0:\n",
    "            temp.append(approach3[j, i])\n",
    "    temp = torch.tensor(temp).reshape(-1)\n",
    "    m = torch.quantile(temp, q = 0.5)\n",
    "    for j in range(unique_users):\n",
    "        if approach1[j, i] == 0:\n",
    "            approach3[j, i] = m\n",
    "            \n",
    "approach3\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 3, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 4, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original matrix :\n",
    "orig = torch.clone(approach1)\n",
    "\n",
    "approach1 = approach1.to(torch.float64)\n",
    "\n",
    "orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate svd for approach 1 :\n",
    "\n",
    "u, s, vT = torch.svd(approach1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "\n",
    "\n",
    "max_args = torch.argsort(torch.abs(s), descending = True)\n",
    "approx1 = torch.zeros((unique_users, unique_movies), dtype = torch.float64)\n",
    "\n",
    "for i in max_args[0:k]:\n",
    "    approx1 += s[i]*torch.outer(u[:, i], vT[:, i])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.8113e+00,  7.1318e-01,  1.7229e-02,  ...,  8.7030e-03,\n",
       "          8.7030e-03,  8.7030e-03],\n",
       "        [-1.2780e-01,  2.6746e+00, -4.8908e-02,  ...,  5.8577e-02,\n",
       "          5.8577e-02,  5.8577e-02],\n",
       "        [-7.0993e-01, -1.7606e-01,  1.3179e-01,  ...,  3.1645e-02,\n",
       "          3.1645e-02,  3.1645e-02],\n",
       "        ...,\n",
       "        [ 3.6403e-01,  6.3054e-01,  5.2106e-02,  ..., -8.1201e-03,\n",
       "         -8.1201e-03, -8.1201e-03],\n",
       "        [ 1.3650e-02,  3.6824e+00, -3.3863e-02,  ..., -1.7561e-02,\n",
       "         -1.7561e-02, -1.7561e-02],\n",
       "        [ 5.8224e-01,  1.0410e-01, -2.9110e-02,  ...,  2.3955e-03,\n",
       "          2.3955e-03,  2.3955e-03]], dtype=torch.float64)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate svd for approach 2 :\n",
    "\n",
    "u, s, vT = torch.svd(approach2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_args = torch.argsort(torch.abs(s), descending = True)\n",
    "approx2 = torch.zeros((unique_users, unique_movies), dtype = torch.float64)\n",
    "\n",
    "for i in max_args[0:k]:\n",
    "    approx2 += s[i]*torch.outer(u[:, i], vT[:, i])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8371, 3.9179, 2.1419,  ..., 2.9997, 2.9997, 2.9997],\n",
       "        [3.7904, 3.3420, 2.1728,  ..., 2.9944, 2.9944, 2.9944],\n",
       "        [3.8530, 4.8800, 1.7928,  ..., 3.0018, 3.0018, 3.0018],\n",
       "        ...,\n",
       "        [4.1068, 4.2264, 2.1569,  ..., 3.0132, 3.0132, 3.0132],\n",
       "        [3.9022, 4.0351, 2.1470,  ..., 3.0035, 3.0035, 3.0035],\n",
       "        [3.9848, 4.2193, 2.1267,  ..., 2.9962, 2.9962, 2.9962]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate svd for approach 3 :\n",
    "\n",
    "u, s, vT = torch.svd(approach3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_args = torch.argsort(torch.abs(s), descending = True)\n",
    "approx3 = torch.zeros((unique_users, unique_movies), dtype = torch.float64)\n",
    "\n",
    "for i in max_args[0:k]:\n",
    "    approx3 += s[i]*torch.outer(u[:, i], vT[:, i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.8167, 3.8361, 2.0047,  ..., 3.0022, 3.0022, 3.0022],\n",
       "        [3.6646, 3.2140, 2.0108,  ..., 3.0047, 3.0047, 3.0047],\n",
       "        [3.9080, 4.6239, 1.6902,  ..., 3.0023, 3.0023, 3.0023],\n",
       "        ...,\n",
       "        [4.1291, 4.0285, 2.0135,  ..., 3.0119, 3.0119, 3.0119],\n",
       "        [3.9053, 4.0022, 2.0039,  ..., 3.0017, 3.0017, 3.0017],\n",
       "        [3.9456, 4.1007, 1.9846,  ..., 2.9956, 2.9956, 2.9956]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate error for each :\n",
    "\n",
    "error1 = 0.0\n",
    "error2 = 0.0\n",
    "error3 = 0.0\n",
    "\n",
    "\n",
    "for i in range(unique_movies):\n",
    "    for j in range(unique_users):\n",
    "        if orig[j, i] == 0:\n",
    "            continue\n",
    "        error1 += (approx1[j, i] - orig[j, i])**2\n",
    "        error2 += (approx2[j, i] - orig[j, i])**2\n",
    "        error3 += (approx3[j, i] - orig[j, i])**2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# errors using 100 singular values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(228740.2163, dtype=torch.float64)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(31097.9462, dtype=torch.float64)"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(33593.4566, dtype=torch.float64)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean > median > all_zeros when k = 100\n",
    "\n",
    "# now calculate error using 50 singular values :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate svd for approach 1 :\n",
    "\n",
    "u, s, vT = torch.svd(approach1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 50\n",
    "\n",
    "\n",
    "max_args = torch.argsort(torch.abs(s), descending = True)\n",
    "approx1 = torch.zeros((unique_users, unique_movies), dtype = torch.float64)\n",
    "\n",
    "for i in max_args[0:k]:\n",
    "    approx1 += s[i]*torch.outer(u[:, i], vT[:, i])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2038e+00,  8.2466e-01, -2.3140e-02,  ...,  3.9850e-02,\n",
       "          3.9850e-02,  3.9850e-02],\n",
       "        [ 5.9003e-01,  2.4602e+00, -1.1012e-01,  ..., -1.4152e-02,\n",
       "         -1.4152e-02, -1.4152e-02],\n",
       "        [ 3.3700e-01,  1.6568e-01,  7.9057e-02,  ...,  3.6260e-02,\n",
       "          3.6260e-02,  3.6260e-02],\n",
       "        ...,\n",
       "        [ 1.2089e+00,  1.4296e-01,  4.3806e-02,  ...,  1.5711e-02,\n",
       "          1.5711e-02,  1.5711e-02],\n",
       "        [ 2.8299e-01,  3.0432e+00, -4.6121e-02,  ...,  4.0142e-04,\n",
       "          4.0142e-04,  4.0142e-04],\n",
       "        [ 9.0050e-02,  4.2745e-01,  2.6801e-02,  ...,  1.1123e-02,\n",
       "          1.1123e-02,  1.1123e-02]], dtype=torch.float64)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate svd for approach 2 :\n",
    "\n",
    "u, s, vT = torch.svd(approach2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_args = torch.argsort(torch.abs(s), descending = True)\n",
    "approx2 = torch.zeros((unique_users, unique_movies), dtype = torch.float64)\n",
    "\n",
    "for i in max_args[0:k]:\n",
    "    approx2 += s[i]*torch.outer(u[:, i], vT[:, i])\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.9395, 4.0015, 2.1432,  ..., 2.9986, 2.9986, 2.9986],\n",
       "        [3.8716, 3.7465, 2.1535,  ..., 2.9974, 2.9974, 2.9974],\n",
       "        [4.0136, 4.4657, 1.9630,  ..., 3.0030, 3.0030, 3.0030],\n",
       "        ...,\n",
       "        [3.9601, 4.0123, 2.1541,  ..., 3.0200, 3.0200, 3.0200],\n",
       "        [3.9043, 4.0403, 2.1718,  ..., 3.0074, 3.0074, 3.0074],\n",
       "        [3.9550, 4.2468, 2.1535,  ..., 2.9941, 2.9941, 2.9941]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate svd for approach 3 :\n",
    "\n",
    "u, s, vT = torch.svd(approach3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_args = torch.argsort(torch.abs(s), descending = True)\n",
    "approx3 = torch.zeros((unique_users, unique_movies), dtype = torch.float64)\n",
    "\n",
    "for i in max_args[0:k]:\n",
    "    approx3 += s[i]*torch.outer(u[:, i], vT[:, i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.9579, 4.0255, 2.0008,  ..., 2.9989, 2.9989, 2.9989],\n",
       "        [3.9250, 3.8685, 1.9993,  ..., 3.0060, 3.0060, 3.0060],\n",
       "        [3.9983, 4.2857, 1.8630,  ..., 2.9976, 2.9976, 2.9976],\n",
       "        ...,\n",
       "        [3.9349, 3.7576, 2.0015,  ..., 3.0210, 3.0210, 3.0210],\n",
       "        [3.8933, 3.9515, 2.0171,  ..., 3.0067, 3.0067, 3.0067],\n",
       "        [3.9840, 4.0944, 1.9981,  ..., 2.9945, 2.9945, 2.9945]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate error for each :\n",
    "\n",
    "error1 = 0.0\n",
    "error2 = 0.0\n",
    "error3 = 0.0\n",
    "\n",
    "\n",
    "for i in range(unique_movies):\n",
    "    for j in range(unique_users):\n",
    "        if orig[j, i] == 0:\n",
    "            continue\n",
    "        error1 += (approx1[j, i] - orig[j, i])**2\n",
    "        error2 += (approx2[j, i] - orig[j, i])**2\n",
    "        error3 += (approx3[j, i] - orig[j, i])**2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(344347.5516, dtype=torch.float64)"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(49889.9045, dtype=torch.float64)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(53743.9466, dtype=torch.float64)"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# again mean > median > all_zeros for when k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate for k = 250 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate svd for approach 1 :\n",
    "\n",
    "u, s, vT = torch.svd(approach1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 250\n",
    "\n",
    "\n",
    "max_args = torch.argsort(torch.abs(s), descending = True)\n",
    "approx1 = torch.zeros((unique_users, unique_movies), dtype = torch.float64)\n",
    "\n",
    "for i in max_args[0:k]:\n",
    "    approx1 += s[i]*torch.outer(u[:, i], vT[:, i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.4211,  0.0377,  0.0447,  ..., -0.0483, -0.0483, -0.0483],\n",
       "        [ 0.4671,  2.3029, -0.0881,  ..., -0.0114, -0.0114, -0.0114],\n",
       "        [ 0.0671,  0.0375,  0.4420,  ...,  0.0067,  0.0067,  0.0067],\n",
       "        ...,\n",
       "        [ 0.4763,  0.5249,  0.1062,  ...,  0.0078,  0.0078,  0.0078],\n",
       "        [-0.0343,  3.9884,  0.0616,  ..., -0.0371, -0.0371, -0.0371],\n",
       "        [ 0.3817, -0.0455, -0.0143,  ..., -0.0185, -0.0185, -0.0185]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate svd for approach 2 :\n",
    "\n",
    "u, s, vT = torch.svd(approach2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_args = torch.argsort(torch.abs(s), descending = True)\n",
    "approx2 = torch.zeros((unique_users, unique_movies), dtype = torch.float64)\n",
    "\n",
    "for i in max_args[0:k]:\n",
    "    approx2 += s[i]*torch.outer(u[:, i], vT[:, i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.5528, 4.0467, 2.1563,  ..., 2.9987, 2.9987, 2.9987],\n",
       "        [3.9016, 3.0267, 2.2129,  ..., 2.9967, 2.9967, 2.9967],\n",
       "        [3.9685, 4.1045, 1.4662,  ..., 3.0014, 3.0014, 3.0014],\n",
       "        ...,\n",
       "        [4.1080, 4.1279, 2.1365,  ..., 3.0065, 3.0065, 3.0065],\n",
       "        [3.9412, 3.8761, 2.1645,  ..., 2.9992, 2.9992, 2.9992],\n",
       "        [3.8502, 4.2052, 2.1609,  ..., 2.9981, 2.9981, 2.9981]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate svd for approach 3 :\n",
    "\n",
    "u, s, vT = torch.svd(approach3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "max_args = torch.argsort(torch.abs(s), descending = True)\n",
    "approx3 = torch.zeros((unique_users, unique_movies), dtype = torch.float64)\n",
    "\n",
    "for i in max_args[0:k]:\n",
    "    approx3 += s[i]*torch.outer(u[:, i], vT[:, i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.6616, 3.9993, 2.0186,  ..., 2.9990, 2.9990, 2.9990],\n",
       "        [3.8400, 2.9023, 2.0380,  ..., 2.9973, 2.9973, 2.9973],\n",
       "        [4.0251, 3.9251, 1.3885,  ..., 3.0071, 3.0071, 3.0071],\n",
       "        ...,\n",
       "        [4.2820, 3.9090, 1.9798,  ..., 3.0087, 3.0087, 3.0087],\n",
       "        [3.9379, 3.8217, 2.0053,  ..., 2.9954, 2.9954, 2.9954],\n",
       "        [3.8853, 3.9913, 2.0064,  ..., 2.9995, 2.9995, 2.9995]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now calculate error for each :\n",
    "\n",
    "error1 = 0.0\n",
    "error2 = 0.0\n",
    "error3 = 0.0\n",
    "\n",
    "\n",
    "for i in range(unique_movies):\n",
    "    for j in range(unique_users):\n",
    "        if orig[j, i] == 0:\n",
    "            continue\n",
    "        error1 += (approx1[j, i] - orig[j, i])**2\n",
    "        error2 += (approx2[j, i] - orig[j, i])**2\n",
    "        error3 += (approx3[j, i] - orig[j, i])**2\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(69038.0956, dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8298.4248, dtype=torch.float64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9034.3107, dtype=torch.float64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in total -> mean > median > all zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "PyTorch Project.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
